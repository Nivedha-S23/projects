{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, we need to install few dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNn0Sx-Ose7L"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade tensorflow dialogflow scipy tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eV-PUfKfiF2q"
   },
   "outputs": [],
   "source": [
    "import dialogflow_v2 as dialogflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from google.colab import auth\n",
    "import pickle\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "xSATtr21thaG"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID=\"\" # Set your GCP Project Id\n",
    "SERVICE_ACCOUNT_EMAIL=\"\" # Set your Dialogflow service account email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDdAAVeVtMCX"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "!gcloud iam service-accounts keys create sa-key.json \\\n",
    " --iam-account={SERVICE_ACCOUNT_EMAIL} --project={PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qao-CnY2u0aV"
   },
   "outputs": [],
   "source": [
    "def fetch_intents_training_phrases(service_account_file, project):\n",
    "\n",
    "  dialogflow_entity_client = dialogflow.EntityTypesClient.from_service_account_file(service_account_file)\n",
    "  parent = dialogflow_entity_client.project_agent_path(project)\n",
    "  entities = list(dialogflow_entity_client.list_entity_types(parent))\n",
    "\n",
    "  dialogflow_intents_client = dialogflow.IntentsClient.from_service_account_file(service_account_file)\n",
    "  parent = dialogflow_intents_client.project_agent_path(project)\n",
    "  intents = list(dialogflow_intents_client.list_intents(\n",
    "    parent=parent,\n",
    "    intent_view=dialogflow.enums.IntentView.INTENT_VIEW_FULL))\n",
    "\n",
    "  entities_name_to_value = {\n",
    "    'date-time': 'tomorrow afternoon',\n",
    "    'date': 'tomorrow',\n",
    "    'date-period': 'April',\n",
    "    'time': '4:30 pm',\n",
    "    'time-period': 'afternoon',\n",
    "    'number': 'one',\n",
    "    'cardinal': 'ten',\n",
    "    'ordinal': 'tenth',\n",
    "    'number-integer': '1',\n",
    "    'number-sequence': '1 2 3',\n",
    "    'flight-number' : 'LH4234',\n",
    "    'unit-area': 'ten square feet',\n",
    "    'unit-currency': '5 dollars',\n",
    "    'unit-length': 'ten meters',\n",
    "    'unit-speed': '5 km/h',\n",
    "    'unit-volume': '2 liters',\n",
    "    'unit-weight': '5 kilos',\n",
    "    'unit-information': '5 megabytes',\n",
    "    'percentage': '10 percent',\n",
    "    'temperature': '25 degrees',\n",
    "    'duration': '5 days',\n",
    "    'age': '1 year old',\n",
    "    'currency-name': 'euros',\n",
    "    'unit-area-name': 'suqare meters',\n",
    "    'unit-length-name': 'meters',\n",
    "    'unit-speed-name': 'kilometer per hour',\n",
    "    'unit-volume-name': 'cubic meters',\n",
    "    'unit-weight-name': 'kilograms',\n",
    "    'unit-information-name': 'megabytes',\n",
    "    'address': '1600 Amphitheatre Pkwy, Mountain View, CA 94043',\n",
    "    'zip-code': '94122',\n",
    "    'geo-capital': 'Rome',\n",
    "    'geo-country': 'Denmark',\n",
    "    'geo-country-code': 'US',\n",
    "    'geo-city': 'Tokyo',\n",
    "    'geo-state': 'Scotland',\n",
    "    'place-attraction': 'Golden Gate Bridge',\n",
    "    'airport': 'SFO',\n",
    "    'location': '1600 Amphitheatre Pkwy, Mountain View, CA 94043',\n",
    "    'email': 'test@example.com',\n",
    "    'phone-number': '+11234567890',\n",
    "    'given-name': 'Joe',\n",
    "    'last-name': 'Smith',\n",
    "    'music-artist': 'Beatles',\n",
    "    'music-genre': 'Jazz',\n",
    "    'color': 'Blue',\n",
    "    'language': 'Japanese',\n",
    "    'any': 'flower',\n",
    "    'url': 'google.com'\n",
    "  }\n",
    "  for intent in intents:\n",
    "      entities_used = {entity.display_name \n",
    "        for entity in intent.parameters}\n",
    "\n",
    "      for entity in entities:\n",
    "          if entity.display_name in entities_used \\\n",
    "                  and entity.display_name not in entities_name_to_value:\n",
    "                  \n",
    "              entities_name_to_value[entity.display_name] = np.random.choice(\n",
    "                  np.random.choice(entity.entities).synonyms, replace=False)\n",
    "\n",
    "  intent_training_phrases = defaultdict(list)\n",
    "  for intent in intents:\n",
    "      for training_phrase in intent.training_phrases:\n",
    "\n",
    "          parts = [\n",
    "              entities_name_to_value[part.alias] \n",
    "              if part.alias in  entities_name_to_value else part.text\n",
    "              for part in training_phrase.parts\n",
    "          ]\n",
    "          intent_training_phrases[intent.display_name].append(\n",
    "              \"\".join(parts))\n",
    "      # Remove intents with no training phrases\n",
    "      if not intent_training_phrases[intent.display_name]:\n",
    "          del intent_training_phrases[intent.display_name]\n",
    "  return intent_training_phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_H98m8dIY0d"
   },
   "outputs": [],
   "source": [
    "intent_training_phrases = fetch_intents_training_phrases(\"sa-key.json\", PROJECT_ID)\n",
    "\n",
    "for intent in intent_training_phrases:\n",
    "  print(\"{}:{}\".format(intent, intent_training_phrases[intent]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rUMUOAIFGW8A"
   },
   "source": [
    "### Let's create some embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQHoK4FOHP9u"
   },
   "outputs": [],
   "source": [
    "embed_module = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XFREDe8kSMc"
   },
   "outputs": [],
   "source": [
    "def make_embeddings_fn():\n",
    "  placeholder = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "  embed = embed_module(placeholder)\n",
    "  session = tf.Session()\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  def _embeddings_fn(sentences):\n",
    "      computed_embeddings = session.run(\n",
    "        embed, feed_dict={placeholder: sentences})\n",
    "      return computed_embeddings\n",
    "  return _embeddings_fn\n",
    "\n",
    "generate_embeddings = make_embeddings_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZLqLTbwl_9f"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "  \"Hi\",\n",
    "  \"Hello\",\n",
    "  \"Goodbye\",\n",
    "  \"I'm a software program\"\n",
    "]\n",
    "computed_embeddings = generate_embeddings(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6rH0THPJUwg"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "point_size=200\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "points_2d = pca.fit_transform(computed_embeddings)\n",
    "\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for point, marker in zip(points_2d, ['o', '^', '*', 's']):\n",
    "  xs = point[0]\n",
    "  ys = point[1]\n",
    "  ax.scatter(xs, ys, marker=marker, s=point_size)\n",
    "\n",
    "ax.set_xlabel('X Dimension')\n",
    "ax.set_ylabel('Y Dimension')\n",
    "\n",
    "ax.legend(sentences)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vumjAEHc3d0J"
   },
   "outputs": [],
   "source": [
    "training_phrases_with_embeddings = defaultdict(list)\n",
    "for intent_name, training_phrases_list in intent_training_phrases.items():\n",
    "  computed_embeddings = generate_embeddings(training_phrases_list)\n",
    "  training_phrases_with_embeddings[intent_name] = dict(zip(training_phrases_list, computed_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EzLKfUJLX3H"
   },
   "outputs": [],
   "source": [
    "for intent_name, _ in training_phrases_with_embeddings.items():\n",
    "  training_phrase, embeddings = next(iter(training_phrases_with_embeddings[intent_name].items()))\n",
    "  print(\"{}: {{'{}':{}}}\".format(intent_name, training_phrase, embeddings[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ck0u6wp86DED"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "embedding_vectors = []\n",
    "\n",
    "for intent, training_phrases_and_embeddings in training_phrases_with_embeddings.items():\n",
    "  for training_phrase, embeddings in training_phrases_and_embeddings.items():\n",
    "    embedding_vectors.append(embeddings)\n",
    "\n",
    "embedding_vectors = np.asarray(embedding_vectors)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(embedding_vectors)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "legend = []\n",
    "\n",
    "for color, intent in enumerate(training_phrases_with_embeddings.keys()):\n",
    "  phrases = list(training_phrases_with_embeddings[intent].keys())\n",
    "  embeddings = list(training_phrases_with_embeddings[intent].values())\n",
    "  points = pca.transform(embeddings)\n",
    "  xs = points[:,0]\n",
    "  ys = points[:,1]\n",
    "  ax.scatter(xs, ys, marker='o', s=100, c=\"C\"+str(color))\n",
    "  for i, phrase in enumerate(phrases):\n",
    "    ax.annotate(phrase[:15] + '...', (xs[i], ys[i]))\n",
    "  legend.append(intent)\n",
    "\n",
    "\n",
    "ax.legend(legend)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q5VM6KqfibRT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity      \n",
    "\n",
    "flatten = []\n",
    "\n",
    "for intent in training_phrases_with_embeddings:\n",
    "  for phrase in training_phrases_with_embeddings[intent]:\n",
    "    flatten.append((intent, phrase,  training_phrases_with_embeddings[intent][phrase]))\n",
    "\n",
    "data = []\n",
    "for i in range(len(flatten)):\n",
    "  for j in range(i+1, len(flatten)):\n",
    "\n",
    "    intent_1 = flatten[i][0]\n",
    "    phrase_1 = flatten[i][1]\n",
    "    embedd_1 = flatten[i][2]\n",
    "\n",
    "    intent_2 = flatten[j][0]\n",
    "    phrase_2 = flatten[j][1]\n",
    "    embedd_2 = flatten[j][2]\n",
    "\n",
    "    similarity = cosine_similarity([embedd_1], [embedd_2])[0][0]\n",
    "\n",
    "    record = [intent_1, phrase_1, intent_2, phrase_2, similarity]\n",
    "    data.append(record)\n",
    "\n",
    "similarity_df = pd.DataFrame(data, \n",
    "  columns=[\"Intent A\", \"Phrase A\", \"Intent B\", \"Phrase B\", \"Similarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VmGZL9h8kShk"
   },
   "outputs": [],
   "source": [
    "different_intent = similarity_df['Intent A'] != similarity_df['Intent B']\n",
    "display(similarity_df[different_intent].sort_values('Similarity', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9IrieApn21z"
   },
   "source": [
    "### Compute Intents Cohesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2mjItlWLVP3"
   },
   "outputs": [],
   "source": [
    "same_intent = similarity_df['Intent A'] == similarity_df['Intent B']\n",
    "cohesion_df = pd.DataFrame(similarity_df[different_intent].groupby('Intent A', as_index=False)['Similarity'].mean())\n",
    "cohesion_df.columns = ['Intent', 'Cohesion']\n",
    "display(cohesion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLpG39zXonvy"
   },
   "outputs": [],
   "source": [
    "different_intent = similarity_df['Intent A'] != similarity_df['Intent B']\n",
    "separation_df = pd.DataFrame(similarity_df[different_intent].groupby(['Intent A', 'Intent B'], as_index=False)['Similarity'].mean())\n",
    "separation_df['Separation'] = 1 - separation_df['Similarity']\n",
    "del separation_df['Similarity']\n",
    "display(separation_df.sort_values('Separation'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[MAKE A COPY] Dialogflow Intent health check.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
